{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read, resize, separate, crop, extract, calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e7857c369b08>:125: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  not_distance = 1.0 / disparity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exiting\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def wrap_position_calculation (frame, position_calculation_method):\n",
    "    SCALE = 5\n",
    "    \n",
    "    CROP_SHIFT = 30\n",
    "    \n",
    "    (YSZ, XSZ, _) = frame.shape\n",
    "    XSZ = int (XSZ / 2)\n",
    "\n",
    "    resized = cv2.resize (frame, (int (XSZ * 2 / SCALE), int (YSZ / SCALE)))\n",
    "\n",
    "    XSZ = int (XSZ / SCALE)\n",
    "    YSZ = int (YSZ / SCALE)\n",
    "\n",
    "    left  = resized [:, : XSZ, :]\n",
    "    right = resized [:, XSZ :, :]\n",
    "\n",
    "    left_crop  = left  [CROP_SHIFT : - CROP_SHIFT, CROP_SHIFT : - CROP_SHIFT, :]\n",
    "    right_crop = right [CROP_SHIFT : - CROP_SHIFT, CROP_SHIFT : - CROP_SHIFT, :]\n",
    "    \n",
    "    position_calculation_method (left_crop, right_crop)\n",
    "\n",
    "def loop_video (video_path, position_calculation_method):\n",
    "    cam = cv2.VideoCapture (video_path)\n",
    "\n",
    "    while (True):\n",
    "        _, frame = cam.read ()\n",
    "\n",
    "        k = cv2.waitKey (10) & 0xFF\n",
    "\n",
    "        if (frame is None):\n",
    "            cam.release ()\n",
    "            cam = cv2.VideoCapture (video_path)\n",
    "\n",
    "        wrap_position_calculation (frame, position_calculation_method)\n",
    "        \n",
    "        if (k == ord('q')):\n",
    "            print (\"exiting\")\n",
    "            break\n",
    "    \n",
    "    cam.release ()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def find_max_bounding_box (mask, bbox_num = 1):\n",
    "    output = cv2.connectedComponentsWithStats (mask, 8, cv2.CV_32S)\n",
    "    stats = output [2]\n",
    "\n",
    "    sorted_components = stats [np.argsort (stats [:, cv2.CC_STAT_AREA])]\n",
    "    sorted_components = sorted_components [: -1]\n",
    "    sorted_components = sorted_components [- min(\n",
    "        bbox_num, len (sorted_components)):]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range (len (sorted_components)):\n",
    "        top = sorted_components [i, cv2.CC_STAT_TOP]\n",
    "        left = sorted_components [i, cv2.CC_STAT_LEFT]\n",
    "        width = sorted_components [i, cv2.CC_STAT_WIDTH]\n",
    "        height = sorted_components [i, cv2.CC_STAT_HEIGHT]\n",
    "\n",
    "        result.append (((left, top), (left + width, top + height)))\n",
    "\n",
    "    return result\n",
    "\n",
    "backgr_subtr_l = cv2.createBackgroundSubtractorMOG2 ()\n",
    "backgr_subtr_r = cv2.createBackgroundSubtractorMOG2 ()\n",
    "\n",
    "def calc_z_by_disparity (left, right):\n",
    "    global backgr_subtr_l\n",
    "    global backgr_subtr_r\n",
    "    \n",
    "    OBJ_LTH = (150, 150, 150)\n",
    "    OBJ_HTH = (255, 255, 255)\n",
    "    \n",
    "    foreground_mask_l = backgr_subtr_l.apply (left)\n",
    "    foreground_mask_r = backgr_subtr_r.apply (right)\n",
    "\n",
    "    color_mask_l = cv2.inRange (left,  OBJ_LTH, OBJ_HTH)\n",
    "    color_mask_r = cv2.inRange (right, OBJ_LTH, OBJ_HTH)\n",
    "\n",
    "    mask_l = cv2.bitwise_and (foreground_mask_l, color_mask_l)\n",
    "    mask_r = cv2.bitwise_and (foreground_mask_r, color_mask_r)\n",
    "    \n",
    "    mask_l_bgr = cv2.cvtColor (mask_l, cv2.COLOR_GRAY2BGR)\n",
    "    mask_r_bgr = cv2.cvtColor (mask_r, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    left_row = np.concatenate ((left,\n",
    "                                cv2.cvtColor(foreground_mask_l, cv2.COLOR_GRAY2BGR),\n",
    "                                cv2.cvtColor(color_mask_l, cv2.COLOR_GRAY2BGR),\n",
    "                                mask_l_bgr), axis=1)\n",
    "\n",
    "    right_row = np.concatenate ((right,\n",
    "                                 cv2.cvtColor(foreground_mask_r, cv2.COLOR_GRAY2BGR),\n",
    "                                 cv2.cvtColor(color_mask_r, cv2.COLOR_GRAY2BGR),\n",
    "                                 mask_r_bgr), axis=1)\n",
    "    \n",
    "    #extract biggest connected component, draw bboxes, stack marked\n",
    "    #images into object_row (+pad with copies)\n",
    "    \n",
    "    l_bboxes = find_max_bounding_box (mask_l)\n",
    "    r_bboxes = find_max_bounding_box (mask_r)\n",
    "    \n",
    "    if (len (l_bboxes) == 0 or len (r_bboxes) == 0):\n",
    "        print (\"skipping frame: no object\")\n",
    "        return\n",
    "\n",
    "    l_bbox = l_bboxes [0]\n",
    "    r_bbox = r_bboxes [0]\n",
    "    \n",
    "    mask_l_marked = cv2.rectangle (mask_l_bgr, l_bbox [0], l_bbox [1], (100, 200, 10), 3)\n",
    "    mask_r_marked = cv2.rectangle (mask_r_bgr, r_bbox [0], r_bbox [1], (100, 200, 10), 3)\n",
    "    \n",
    "    object_row = np.concatenate ((mask_l_marked, mask_r_marked, mask_r_marked, mask_r_marked),\n",
    "                                axis=1)\n",
    "\n",
    "    #concatenate left_row, right_row, object_row along 0 axis\n",
    "    result = np.concatenate ((left_row, right_row, object_row), axis=0)\n",
    "\n",
    "    #subtract bbox middle points' x (disparity)\n",
    "    disparity = (l_bbox [0] [0] + l_bbox [1] [0]) / 2 - (r_bbox [0] [0] + r_bbox [1] [0]) / 2\n",
    "    \n",
    "    #1 / disparity * scale \\approx distance\n",
    "    not_distance = 1.0 / disparity\n",
    "    \n",
    "    #cv2. write distance over the frame\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    org = (50, 50) \n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    image = cv2.putText (result, 'not distance: ' + str (not_distance), org, font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    #cv2.imshow (\"left\", left_row)\n",
    "    #cv2.imshow (\"right\", right_row)\n",
    "\n",
    "    cv2.imshow (\"stages\", result)\n",
    "\n",
    "#def calc_z_by_point_cloud (left, right):\n",
    "    \n",
    "\n",
    "video_path = \"/Users/elijah/Documents/stereopi/video.avi\"\n",
    "\n",
    "loop_video (video_path, calc_z_by_disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{3}{5}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
